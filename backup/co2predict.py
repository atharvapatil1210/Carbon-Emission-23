# -*- coding: utf-8 -*-
"""CO2Predict.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j4bYkFi-0nUmgH5U3ZMc3vGKh1mZgv2V

# Predictive Analysis
To implement Predictive Analytics for forecasting future emissions and suggesting reduction strategies, we need to take the following steps:
1. **Data Preprocessing and Feature Engineering:**
*	Before building predictive models, ensure that the dataset is cleaned and preprocessed.
*	You may need to create additional features (e.g., **day of the week, month, seasonality, historical emission trends, etc.**) that may influence future emissions.
2. **Model Selection:**
*	For time series forecasting, common models include:
  *	**ARIMA (AutoRegressive Integrated Moving Average):** Useful for univariate time series data where trends and seasonality can be captured.
  *	**Prophet:** Developed by Facebook, useful for handling seasonality and holidays with more flexibility than ARIMA.
  *	**LSTM (Long Short-Term Memory):** A type of neural network suitable for sequential data (time series) if you need deep learning approaches.
*	**For emission reduction strategies:**
  *	After predicting future emissions, use optimization techniques or linear regression to estimate the impact of different strategies on emissions (e.g., reducing energy consumption, improving logistics, changing manufacturing processes).
3. **Time Series Forecasting:**
*	Build a time series model (e.g., ARIMA or Prophet) to predict future emissions based on historical data.
*	Evaluation: Evaluate the model using metrics like **Mean Absolute Error (MAE)**, **Mean Squared Error (MSE)**, or **R² score**.
4. **Emissions Reduction Strategies:**
*	Identify key sources of emissions from the data.
*	Create a set of potential reduction strategies (e.g., improving energy efficiency, switching to renewable energy, optimizing logistics, etc.).
*	Model how these strategies could impact emissions by simulating different scenarios.
"""

# Step 1: Install necessary packages
!pip install prophet matplotlib

# Step 2: Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
from prophet import Prophet
from sklearn.metrics import mean_absolute_error

# Step 4: Load the emissions dataset
final_df = pd.read_csv('/content/dataset_csv/combined_co2_emissions.csv')

# Step 5: Prepare the Data for Time Series Forecasting
# Ensure 'Date' is in datetime format
final_df['Date'] = pd.to_datetime(final_df['Date'])

# Aggregate emissions data by Date (sum of all sources)
time_series_data = final_df.groupby('Date')['Total_CO2_Emissions (kg)'].sum().reset_index()

# Set 'Date' as index for time series modeling
time_series_data.set_index('Date', inplace=True)

# Check the data
print(time_series_data.head())

# Step 6: Time Series Forecasting using Prophet
# Prepare the data for Prophet (it expects a DataFrame with 'ds' and 'y' columns)
df_prophet = time_series_data.reset_index()
df_prophet.columns = ['ds', 'y']

# Create and fit the Prophet model
model = Prophet()
model.fit(df_prophet)

# Make a dataframe for future predictions (predict for the next 12 months)
future = model.make_future_dataframe(periods=12, freq='M')  # No need for df_prophet argument

# Predict future emissions
forecast = model.predict(future)

# Plot the forecast
model.plot(forecast)
plt.title("CO2 Emissions Forecast for the Next 12 Months")
plt.show()

"""**Step 7: Model Evaluation (Optional, assuming actual emissions test set available):**

 You can compare predicted values to actual values if available

Example code to calculate Mean Absolute Error (MAE)


"""

# Assuming you have a separate test set of actual emissions to compare
# actual_values = test_set['y']  # Replace with actual test set data
# predicted_values = forecast['yhat'][-len(test_set):]  # Use the last predictions that correspond to the test set

# Calculate MAE (uncomment if you have a test set)
# mae = mean_absolute_error(actual_values, predicted_values)
# print(f"Mean Absolute Error (MAE): {mae}")

"""**Step 8: Emissions Reduction Strategies**

Once we have the forecasted emissions, we can implement **a simple strategy to suggest reduction options**. This would be based on historical data of emission sources, and we can simulate a few strategies. For simplicity, let’s assume:
1.	**Energy Efficiency**: Reduce emissions from electricity usage (Scope 2).
2.	**Logistics Optimization**: Reduce emissions from transportation (Scope 3).
3.	**Renewable Energy**: Transition to renewable energy sources to reduce emissions.

"""

# Step 8: Emissions Reduction Strategies (Simulating reductions)
def simulate_strategies(df):
    # Simulate reducing Scope 2 emissions by 10% (e.g., energy efficiency)
    df['Scope_2_Reduction_10%'] = df['CO2 Emissions (kg CO2)_electricity'] * 0.9

    # Simulate reducing Scope 3 emissions by 15% (e.g., logistics optimization)
    df['Scope_3_Reduction_15%'] = df['CO2 Emissions (kg)_logistics'] * 0.85

    # Simulate transitioning to 50% renewable energy for Scope 2
    df['Scope_2_Renewable_50%'] = df['CO2 Emissions (kg CO2)_electricity'] * 0.5

    return df

# Apply strategies to the data
final_df = simulate_strategies(final_df)

# Visualize the impact of these strategies on emissions over time
plt.figure(figsize=(12, 6))
plt.plot(final_df['Date'], final_df['CO2 Emissions (kg CO2)_electricity'], label='Original Scope 2 Emissions')
plt.plot(final_df['Date'], final_df['Scope_2_Reduction_10%'], label='10% Reduction in Scope 2')
plt.plot(final_df['Date'], final_df['Scope_2_Renewable_50%'], label='50% Renewable Energy in Scope 2')

plt.xlabel('Date')
plt.ylabel('CO2 Emissions (kg)')
plt.title('Impact of Emissions Reduction Strategies on Scope 2 Emissions')
plt.legend()
plt.show()

# Step 9: Save the updated dataset with the strategies applied
final_df.to_csv('/content/report/combined_co2_emissions_with_reduction_strategies.csv')

"""**Future Improvements:**
*	Fine-tune the model with more sophisticated algorithms (e.g., LSTM for deep learning).
*	Implement real-time predictions using data from IoT sensors for near-instant feedback.
*	Build a more robust set of reduction strategies and integrate them into the business operations for actionable insights.

"""

